27 bits are not enough for 8digit accuracy from the inequality 108 227 we are likely to conclude that we can represent 8digit decimal floatingpoint numbers accurately by 27bit floatingpoint numbers however we need 28 significant bits to represent some 8digit numbers accurately in general we can show that if 10p 2q1 then q significant bits are always enough for pdigit decimal accuracy finally we can define a compact 27bit floatingpoint representation that will give 28 significant bits for numbers of practical importance cacm february 1967 goldberg i b ca670208 jb february 28 1978 238 pm 1634 5 1634 1634 5 1634 1634 5 1634 1783 5 1634 1843 5 1634 1634 6 1634 1634 6 1634 1783 6 1634 